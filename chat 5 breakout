# breakout_detection.py
from __future__ import annotations
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Tuple
import re, sys, os, glob
import pandas as pd

EXCEL_FILES = ["SMA 1_10.xlsx", "SMA 11_20.xlsx", "SMA 21_28.xlsx"]
DEFAULT_LOOKBACK = 4
DEFAULT_OUTFILE = "fibbreakout-fiborigin.csv"

COLUMN_ALIASES: Dict[str, List[str]] = {
    "time":  ["time", "Time", "datetime", "timestamp", "date", "Date"],
    "open":  ["open", "Open"],
    "high":  ["high", "High"],
    "low":   ["low", "Low"],
    "close": ["close", "Close", "c"],
    "upper": ["Upper", "upper", "keltner_upper", "BB_Upper", "UpperBand"],
    "lower": ["Lower", "lower", "keltner_lower", "BB_Lower", "LowerBand"],
    "smma75": ["SMMA.1"],  # 75er MUSS exakt so heißen
}

CUT_ALIASES: Dict[str, List[str]] = {
    "pair":      ["Pair", "pair", "symbol", "sheet"],
    "start":     ["Start Date", "start", "from", "Start"],
    "end":       ["End Date", "end", "to", "End"],
    "direction": ["Direction", "direction", "signal"],
}

def _norm(s: str) -> str:
    return re.sub(r"[^a-z0-9]+", "", str(s).strip().lower())

def _build_alias_map(aliases: Dict[str, List[str]]) -> Dict[str, str]:
    m = {}
    for canon, alist in aliases.items():
        for a in alist:
            m[_norm(a)] = canon
    return m

def _normalize_columns(df: pd.DataFrame, aliases: Dict[str, List[str]]) -> pd.DataFrame:
    amap = _build_alias_map(aliases)
    # Header reinigen (Mehrfachspaces → 1 Space)
    df.columns = [re.sub(r"\s+", " ", str(c)).strip() for c in df.columns]
    return df.rename(columns={c: (amap.get(_norm(c), c)) for c in df.columns})

def _ensure_utc(ts) -> pd.Timestamp:
    t = pd.to_datetime(ts, errors="coerce")
    if t is None or pd.isna(t): return t
    if getattr(t, "tz", None) is None: return t.tz_localize("UTC")
    return t.tz_convert("UTC")

def _end_exclusive_if_date_like(t: pd.Timestamp) -> pd.Timestamp:
    if pd.isna(t): return t
    if t.hour == 0 and t.minute == 0 and t.second == 0 and t.nanosecond == 0:
        return t + pd.Timedelta(days=1)
    return t

# ---------------- Excel Loader ----------------

class PriceBook:
    def __init__(self, excel_files: Iterable[str] = EXCEL_FILES):
        self.files = [Path(p) for p in excel_files]
        self.sheet_index = self._index()

    def _index(self) -> Dict[str, Path]:
        idx: Dict[str, Path] = {}
        for f in self.files:
            if not f.exists(): continue
            x = pd.ExcelFile(f)
            for sheet in x.sheet_names:
                idx[sheet] = f
        if not idx:
            raise FileNotFoundError("Keine Excel-Dateien gefunden: " + ", ".join(EXCEL_FILES))
        return idx

    def load(self, pair: str) -> pd.DataFrame:
        key = next((s for s in self.sheet_index if s.lower()==pair.lower()), None)
        if key is None:
            raise ValueError(f"Unbekanntes Pair/Sheet: {pair}")
        df = pd.read_excel(self.sheet_index[key], sheet_name=key)
        df = _normalize_columns(df, COLUMN_ALIASES)

        required = {"time","open","high","low","close","upper","lower","smma75"}
        missing = [c for c in required if c not in df.columns]
        if missing:
            raise ValueError(f"[{pair}] Fehlende Spalten {missing}. Erwartet u.a. 'SMMA.1' als smma75.")

        for col in ["open","high","low","close","upper","lower","smma75"]:
            df[col] = pd.to_numeric(df[col], errors="coerce")
        df["time"] = pd.to_datetime(df["time"], errors="coerce", utc=True)
        df = df.dropna(subset=["time"]).sort_values("time").reset_index(drop=True)
        return df

# ---------------- Detection ----------------

def _find_runs(df: pd.DataFrame, start_mask: pd.Series, stay_mask: pd.Series) -> List[Tuple[int,int]]:
    runs: List[Tuple[int,int]] = []
    n = len(df)
    starts = df.index[start_mask.fillna(False)]
    for si in starts:
        if si>0 and bool(stay_mask.iloc[si-1]):  # nicht mitten im Run starten
            continue
        ei = si
        j = si
        while j<n and bool(stay_mask.iloc[j]):
            ei = j; j += 1
        if ei >= si:
            runs.append((si, ei))
    return runs

def _extreme(df: pd.DataFrame, si: int, ei: int, lookback: int, kind: str):
    lo = max(0, si - lookback)
    hi = min(len(df)-1, ei + lookback)
    win = df.loc[lo:hi]
    if kind=="high":
        idx = win["high"].idxmax()
        return df.loc[idx,"time"], float(df.loc[idx,"high"])
    else:
        idx = win["low"].idxmin()
        return df.loc[idx,"time"], float(df.loc[idx,"low"])

def _signals_for_mode(df: pd.DataFrame, mode: str, direction: str, windows, lookback: int) -> List[Dict]:
    c,u,l,m = df["close"], df["upper"], df["lower"], df["smma75"]

    if mode=="breakout":
        if direction=="long":
            start = (c>u) & (c>m); stay = (c>u); name="Long Breakout"; extreme="high"
        else:
            start = (c<l) & (c<m); stay = (c<l); name="Short Breakout"; extreme="low"
    elif mode=="origin":
        if direction=="long":
            start = (c<l); stay = (c<l); name="Fib Long Origin"; extreme="high"
        else:
            start = (c>u); stay = (c>u); name="Fib Short Origin"; extreme="low"
    else:
        raise ValueError("mode must be 'breakout' or 'origin'")

    runs = _find_runs(df, start, stay)
    out=[]
    for si,ei in runs:
        st, et = df.loc[si,"time"], df.loc[ei,"time"]
        if windows and not any((st>=ws) and (st<we) for (ws,we) in windows):
            continue
        xt_t, xt_p = _extreme(df, si, ei, lookback, extreme)
        out.append({
            "signal_type": name,
            "direction": "Long" if direction=="long" else "Short",
            "start_time": st, "end_time": et,
            "extreme_time": xt_t, "extreme_price": xt_p,
        })
    return out

# ---------------- CUT Loader ----------------

def _diagnostic_file_error(target: Path) -> str:
    here = Path.cwd()
    files = "\n".join(sorted(p.name for p in here.iterdir() if p.is_file()))
    return (f"CUT-Datei nicht gefunden/leer: {target}\n"
            f"Arbeitsverzeichnis: {here}\n"
            f"Vorhandene Dateien:\n{files}\n"
            f"Tipp: --cut auf korrekten Pfad setzen oder Datei umbenennen.")

def _read_table_any(path: Path) -> pd.DataFrame:
    try:
        df = pd.read_csv(path, sep=None, engine="python", comment="#")
    except pd.errors.EmptyDataError:
        raise FileNotFoundError(_diagnostic_file_error(path))
    except Exception:
        df = pd.DataFrame()

    if df.empty or len(df.columns) == 1:
        try:
            df = pd.read_csv(path, sep="\t", engine="python", comment="#")
        except Exception:
            df = pd.DataFrame()

    if df.empty or len(df.columns) == 1:
        try:
            df = pd.read_csv(path, delim_whitespace=True, engine="python", comment="#")
        except Exception:
            raise FileNotFoundError(_diagnostic_file_error(path))
    return df

def _find_cut_path(cli_path: Optional[str]) -> Path:
    if cli_path:
        p = Path(cli_path)
        if p.exists(): return p
    patterns = [
        "COTsignalsoutput.tsv",  "COTsignalsoutput.csv",
        "COTsignalsoutputs.tsv", "COTsignalsoutputs.csv",
        "CUTsignalsoutput.tsv",  "CUTsignalsoutput.csv",
        "CutSignalsOutput.tsv",  "CutSignalsOutputs.tsv",
        "*signalsoutput*.tsv",   "*signalsoutput*.csv",
        "*signalsoutputs*.tsv",  "*signalsoutputs*.csv",
    ]
    for pat in patterns:
        hits = sorted(Path(".").glob(pat))
        if hits: return hits[0]
    return Path("COTsignalsoutput.tsv")

def load_cut(cli_path: Optional[str]) -> pd.DataFrame:
    p = _find_cut_path(cli_path)
    if not p.exists():
        raise FileNotFoundError(_diagnostic_file_error(p))
    df = _read_table_any(p)
    df = _normalize_columns(df, CUT_ALIASES)

    req = {"pair","start","end","direction"}
    miss = [c for c in req if c not in df.columns]
    if miss:
        raise ValueError("CUT: fehlende Spalten "
                         f"{miss}. Erwartet Header wie: Start Date   End Date   Direction   Pair")

    df["start"] = df["start"].apply(_ensure_utc)
    df["end"]   = df["end"].apply(_ensure_utc).apply(_end_exclusive_if_date_like)
    df = df.dropna(subset=["start","end"]).reset_index(drop=True)
    df["direction"] = (
        df["direction"].astype(str).str.strip().str.lower()
        .map({"long":"long","short":"short","buy":"long","sell":"short"})
    )
    if df["direction"].isna().any():
        bad = df[df["direction"].isna()]
        raise ValueError(f"CUT: unklare Direction in Zeilen: {bad.index.tolist()}")
    df["pair"] = df["pair"].astype(str)
    return df

# ---------------- Main ----------------

def main():
    import argparse
    p = argparse.ArgumentParser(description="Fib Breakout & Origin Finder (KC + SMMA.1, CUT TSV/CSV)")
    p.add_argument("--cut", default=None, help="Pfad zu COT/CUT (TSV/CSV). Wenn leer, wird automatisch gesucht.")
    p.add_argument("--lookback", type=int, default=DEFAULT_LOOKBACK, help="± Kerzen um Start/Ende")
    p.add_argument("--out", default=DEFAULT_OUTFILE, help="Output CSV (Default: fibbreakout-fiborigin.csv)")
    args = p.parse_args()

    book = PriceBook()
    cut  = load_cut(args.cut)

    rows=[]
    for _, r in cut.iterrows():
        pair = str(r["pair"]); ws, we = r["start"], r["end"]; want = r["direction"]
        df = book.load(pair)
        windows=[(ws,we)]
        for mode in ("breakout","origin"):
            recs = _signals_for_mode(df, mode, want, windows, args.lookback)
            for rec in recs:
                rows.append({
                    "pair": pair,
                    "window_start": ws,
                    "window_end": we,
                    **rec
                })

    out_cols = ["pair","signal_type","direction","window_start","window_end",
                "start_time","end_time","extreme_time","extreme_price"]
    out = pd.DataFrame(rows)[out_cols].sort_values(
        ["pair","signal_type","start_time"]
    ).reset_index(drop=True)

    out.to_csv(args.out, index=False)
    print(f"✅ done. Wrote: {args.out}")
    if not out.empty:
        print(out.head(min(12, len(out))).to_string(index=False))

if __name__ == "__main__":
    main()

